# Integration tests for Smart Chinese analysis components
#
"Tokenizer":
    - skip:
        features: warnings
    - do:
        warnings:
          - text request parameter is deprecated and will be removed in the next major release. Please use the JSON in the request body instead request param
          - tokenizer request parameter is deprecated and will be removed in the next major release. Please use the JSON in the request body instead request param
        indices.analyze:
          text:         我购买了道具和服装。
          tokenizer:    smartcn_tokenizer
    - length: { tokens: 7 }
    - match:  { tokens.0.token: 我  }
    - match:  { tokens.1.token: 购买 }
    - match:  { tokens.2.token: 了 }
    - match:  { tokens.3.token: 道具 }
    - match:  { tokens.4.token: 和 }
    - match:  { tokens.5.token: 服装 }
    - match:  { tokens.6.token: "," }
---
"Analyzer":
    - skip:
        features: warnings
    - do:
        warnings:
          - text request parameter is deprecated and will be removed in the next major release. Please use the JSON in the request body instead request param
          - analyzer request parameter is deprecated and will be removed in the next major release. Please use the JSON in the request body instead request param
        indices.analyze:
          text:         我购买了道具和服装。
          analyzer:     smartcn
    - length: { tokens: 6 }
    - match:  { tokens.0.token: 我  }
    - match:  { tokens.1.token: 购买 }
    - match:  { tokens.2.token: 了 }
    - match:  { tokens.3.token: 道具 }
    - match:  { tokens.4.token: 和 }
    - match:  { tokens.5.token: 服装 }
